{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test & Deploy: Advertising\n",
    "\n",
    "> https://www.statlearning.com/s/Advertising.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # aws python sdk\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import IPython\n",
    "import os\n",
    "\n",
    "# what version\n",
    "print(\"SageMaker Version: \" + sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM role you created when you set everything up\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create a sagemaker sessipn\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# what region are we in?\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "# sdk sagemaker object\n",
    "sm = boto3.Session().client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have experimental capabilities\n",
    "\n",
    "!pip install sagemaker-experiments \n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the raw data will be stored (you will need to change this one)\n",
    "rawbucket = \"dm-raw\"\n",
    "\n",
    "# sklearn framework version\n",
    "framework_version = \"0.20.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# this will allow us to use sklearn to process data\n",
    "sklearn_processor = SKLearnProcessor(framework_version=framework_version,\n",
    "                                     role=role,\n",
    "                                     instance_type=\"ml.c5.xlarge\",\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file locally\n",
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "\n",
    "# this is best practice to make sure it is run at the right time\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Reading input data\")\n",
    "    \n",
    "    df = pd.read_csv(\"/opt/ml/processing/input/Advertising.csv\", index_col=0)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    # feature selection\n",
    "    features = [\n",
    "        'TV'\n",
    "        , 'radio'\n",
    "        , 'newspaper'\n",
    "    ]\n",
    "\n",
    "    # target\n",
    "    target = \"sales\"\n",
    "\n",
    "    # target\n",
    "    y = df[target]\n",
    "\n",
    "    # feature set\n",
    "    X = df[features]\n",
    "    \n",
    "    print(\"Splitting data\")\n",
    "\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    # output directories\n",
    "    train_path = \"/opt/ml/processing/train/\"\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    \n",
    "    print(\"Transfering data to storeage\")\n",
    "    \n",
    "    # train output\n",
    "    X_train.to_csv(train_path + \"X_train.csv\", header=True)\n",
    "    y_train.to_csv(train_path + \"y_train.csv\", header=True)\n",
    "\n",
    "    # test output\n",
    "    X_test.to_csv(test_path + \"X_test.csv\", header=True)\n",
    "    y_test.to_csv(test_path + \"y_test.csv\", header=True)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the script to s3\n",
    "codeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=\"code\")\n",
    "\n",
    "print(codeupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# run the data processing on a dedicated vm\n",
    "sklearn_processor.run(\n",
    "    code=codeupload,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=f\"s3://{rawbucket}/data\",\n",
    "        destination='/opt/ml/processing/input')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='train_data',\n",
    "        source='/opt/ml/processing/train',\n",
    "        destination=f\"s3://{rawbucket}/train\"),\n",
    "        ProcessingOutput(output_name='test_data',\n",
    "        source=\"/opt/ml/processing/test\",\n",
    "        destination=f\"s3://{rawbucket}/test\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# give us some info on the process\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "# show us what happened with the processing\n",
    "print(preprocessing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SageMaker Experiment\n",
    "mmm_experiment = Experiment.create(\n",
    "    experiment_name=f\"mmm-train-{int(time.time())}\", \n",
    "    description=\"Predict sales given a marketing mix\",\n",
    "    sagemaker_boto_client=sm\n",
    ")\n",
    "\n",
    "# show experiment details\n",
    "print(mmm_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tracking parameters used in the Pre-processing pipeline.\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mmm-raw-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/data\")\n",
    "    tracker.log_input(name=\"mmm-train-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/train\")\n",
    "    tracker.log_input(name=\"mmm-test-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the trial\n",
    "trial_name = f\"mmm-training-job-{int(time.time())}\"\n",
    "\n",
    "# create a new trial\n",
    "mmm_trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=mmm_experiment.experiment_name,\n",
    "    sagemaker_boto_client=sm\n",
    ")\n",
    "\n",
    "# add a trial component\n",
    "mmm_trial.add_trial_component(tracker.trial_component)\n",
    "\n",
    "# give the training run a name\n",
    "mmm_training_job_name = \"cc-training-job-{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "# training script\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # data, model, and output directories. you don't have to specify these\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    \n",
    "    # get the arguments\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # load the training data from s3\n",
    "    X_train = pd.read_csv(os.path.join(args.train, \"X_train.csv\"), index_col=0)\n",
    "    y_train = pd.read_csv(os.path.join(args.train, \"y_train.csv\"), index_col=0)\n",
    "\n",
    "    # initialise estimator\n",
    "    reg = linear_model.LinearRegression()\n",
    "    \n",
    "    # train\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate in-sample root-mean-squared-error\n",
    "    in_sample_rmse = metrics.mean_squared_error(y_train, reg.predict(X_train), squared=False)\n",
    "    \n",
    "    # print the rmse, this will appear in the log and will be captured by sagemaker\n",
    "    print(f\"IS-RMSE: {in_sample_rmse}\")\n",
    "    \n",
    "    # save the model to the model directory\n",
    "    joblib.dump(reg, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "\n",
    "# this is a required step to successfully deploy the model\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    reg = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# define a sklearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    metric_definitions=[ # these metrics will be logged and picked up by sagemaker for reporting\n",
    "        {\"Name\": \"train:rmse\", \"Regex\": \"IS-RMSE: ([0-9.]+).*$\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train the estimator\n",
    "sklearn_estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": f\"s3://{rawbucket}/train\"\n",
    "        #, \"test\": f\"s3://{rawbucket}/test\"\n",
    "    },\n",
    "    job_name=mmm_training_job_name,\n",
    "    experiment_config={\n",
    "        \"TrialName\": cc_trial.trial_name, #log training job in Trials for lineage\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most recent trained estimator\n",
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "\n",
    "# find where it is stored\n",
    "artifact = sm.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "# tell us\n",
    "print(f\"Model artifact persisted at {artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# import the model from the location specified\n",
    "model = SKLearnModel(\n",
    "    model_data=artifact,\n",
    "    role=role,\n",
    "    entry_point=\"train.py\",\n",
    "    framework_version=framework_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model and get the endpoint (this might take some time)\n",
    "predictor = model.deploy(instance_type=\"ml.m5.xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test data (features)\n",
    "X_test = pd.read_csv(f\"s3://{rawbucket}/test/X_test.csv\", index_col=0)\n",
    "\n",
    "# look at the test data (features)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the test data to the endpoint\n",
    "predicted = predictor.predict(X_test)\n",
    "\n",
    "# load the actual values\n",
    "actual = pd.read_csv(f\"s3://{rawbucket}/test/y_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# calculate the rmse\n",
    "rmse = metrics.mean_squared_error(actual, predicted, squared=False)\n",
    "\n",
    "print(f\"Test-set RMSE = {rmse}\")\n",
    "\n",
    "# show a plot of test-set predictions and actual values\n",
    "plt.scatter(actual, predicted)\n",
    "plt.plot([0, 25], [0, 25], '--', linewidth=1, c=\"b\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=\"sagemaker-scikit-learn-2021-06-16-01-21-39-258\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb\n",
    "\n",
    "https://aws.amazon.com/getting-started/hands-on/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=gs_card"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
