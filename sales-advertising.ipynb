{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM role\n",
    "role = get_execution_role()\n",
    "\n",
    "print(f\"Role = {role}\")\n",
    "\n",
    "# create a sagemaker sessipn\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "# what region are we in?\n",
    "print(f\"Region = {region}\")\n",
    "\n",
    "# sdk sagemaker object\n",
    "sm = boto3.Session().client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep, gmtime, strftime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we have experiment capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-experiments \n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the raw data will be stored\n",
    "rawbucket = \"dm-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type=\"ml.c5.xlarge\",\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print(\"Reading input data\")\n",
    "    \n",
    "    df = pd.read_csv(\"/opt/ml/processing/input/Advertising.csv\", index_col=0)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    features = [\n",
    "        'TV'\n",
    "        , 'radio'\n",
    "        , 'newspaper'\n",
    "    ]\n",
    "\n",
    "    target = \"sales\"\n",
    "\n",
    "    y = df[target]\n",
    "\n",
    "    X = df[features]\n",
    "    \n",
    "    print(\"Splitting data\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    train_path = \"/opt/ml/processing/train/\"\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    \n",
    "    print(\"Outputting data\")\n",
    "    \n",
    "    # train output\n",
    "    X_train.to_csv(train_path + \"X_train.csv\", header=True)\n",
    "    y_train.to_csv(train_path + \"y_train.csv\", header=True)\n",
    "\n",
    "    # test output\n",
    "    X_test.to_csv(test_path + \"X_test.csv\", header=True)\n",
    "    y_test.to_csv(test_path + \"y_test.csv\", header=True)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the preprocessing code over to the s3 bucket\n",
    "codeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=\"code\")\n",
    "\n",
    "print(codeupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code=codeupload,\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=f\"s3://{rawbucket}/data\",\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train',\n",
    "                               destination=f\"s3://{rawbucket}/train\"),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source=\"/opt/ml/processing/test\",\n",
    "                                               destination=f\"s3://{rawbucket}/test\")\n",
    "                              ]\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SageMaker Experiment\n",
    "cc_experiment = Experiment.create(\n",
    "    experiment_name=f\"Build-train-deploy-{int(time.time())}\", \n",
    "    description=\"Predict sales given a marketing mix\",\n",
    "    sagemaker_boto_client=sm)\n",
    "\n",
    "print(cc_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tracking parameters used in the Pre-processing pipeline.\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"ccdefault-raw-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/data\")\n",
    "    tracker.log_input(name=\"ccdefault-train-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/train\")\n",
    "    tracker.log_input(name=\"ccdefault-test-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = f\"cc-default-training-job-{int(time.time())}\"\n",
    "cc_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "            experiment_name=cc_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm\n",
    "    )\n",
    "\n",
    "cc_trial.add_trial_component(preprocessing_trial_component)\n",
    "cc_training_job_name = \"cc-training-job-{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "# training script\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    X_train = pd.read_csv(os.path.join(args.train, \"X_train.csv\"), index_col=0)\n",
    "    y_train = pd.read_csv(os.path.join(args.train, \"y_train.csv\"), index_col=0)\n",
    "\n",
    "    reg = linear_model.LinearRegression()\n",
    "    \n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    in_sample_rmse = metrics.mean_squared_error(y_train, reg.predict(X_train), squared=False)\n",
    "    \n",
    "    print(f\"IS-RMSE: {in_sample_rmse}\")\n",
    "    \n",
    "    joblib.dump(reg, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    reg = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn('train.py',\n",
    "                            instance_type=\"ml.c5.xlarge\",\n",
    "                            framework_version='0.20.0',\n",
    "                            role=role,\n",
    "                            metric_definitions=[{\"Name\": \"train:rmse\", \"Regex\": \"IS-RMSE: ([0-9.]+).*$\"}]\n",
    "                           )\n",
    "\n",
    "sklearn_estimator.fit(\n",
    "    inputs={\"train\": f\"s3://{rawbucket}/train\", \"test\": f\"s3://{rawbucket}/test\"},\n",
    "    job_name=cc_training_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": cc_trial.trial_name, #log training job in Trials for lineage\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "\n",
    "artifact = sm.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=artifact,\n",
    "    role=get_execution_role(),\n",
    "    entry_point=\"train.py\",\n",
    "    framework_version='0.20.0',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = model.deploy(instance_type=\"ml.m5.xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = pd.read_csv(f\"s3://{rawbucket}/test/X_test.csv\", index_col=0)\n",
    "\n",
    "#X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = predictor.predict(X_test)\n",
    "\n",
    "#actual = pd.read_csv(f\"s3://{rawbucket}/test/y_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn import metrics\n",
    "\n",
    "#mse = metrics.mean_squared_error(actual, predicted, squared=False)\n",
    "\n",
    "#print(f\"Test-set RMSE = {mse}\")\n",
    "\n",
    "#plt.scatter(actual, predicted)\n",
    "#plt.plot([0, 25], [0, 25], '--', linewidth=2, c=\"r\")\n",
    "#plt.xlabel(\"Actual Sales\")\n",
    "#plt.ylabel(\"Predicted Sales\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm.delete_endpoint(EndpointName=predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
