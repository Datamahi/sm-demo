{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test & Deploy: Advertising\n",
    "\n",
    "> https://www.statlearning.com/s/Advertising.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # aws python sdk\n",
    "import sagemaker # aws sagemaker\n",
    "import numpy as np # numerical python\n",
    "import pandas as pd # python for data analysis\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import IPython\n",
    "import os\n",
    "\n",
    "# what version\n",
    "print(\"SageMaker Version: \" + sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM role you created when you set everything up\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create a sagemaker sessipn\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# what region are we in?\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "# sdk sagemaker object\n",
    "sm = boto3.Session().client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the raw data is stored\n",
    "#rawbucket = \"\"\n",
    "\n",
    "# sklearn framework version\n",
    "framework_version = \"0.20.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# this will allow us to use sklearn to process data\n",
    "sklearn_processor = SKLearnProcessor(framework_version=framework_version,\n",
    "                                     role=role,\n",
    "                                     instance_type=\"ml.c5.xlarge\",\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "import os\n",
    "\n",
    "# this is best practice to make sure it is run at the right time\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Reading input data\")\n",
    "    \n",
    "    df = pd.read_csv(\"/opt/ml/processing/input/Advertising.csv\", index_col=0)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    # feature selection\n",
    "    features = [\n",
    "        'TV'\n",
    "        , 'radio'\n",
    "        , 'newspaper'\n",
    "    ]\n",
    "\n",
    "    # target\n",
    "    target = \"sales\"\n",
    "\n",
    "    # target\n",
    "    y = df[target]\n",
    "\n",
    "    # feature set\n",
    "    X = df[features]\n",
    "    \n",
    "    print(\"Splitting data\")\n",
    "\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    # output directories\n",
    "    train_path = \"/opt/ml/processing/train/\"\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    \n",
    "    print(\"Transfering data to storage\")\n",
    "    \n",
    "    # train output\n",
    "    datasets.dump_svmlight_file(X_train, y_train, train_path + \"train\")\n",
    "    \n",
    "    # test output\n",
    "    X_test.to_csv(test_path + \"X_test.csv\", header=True)\n",
    "    y_test.to_csv(test_path + \"y_test.csv\", header=True)\n",
    "    \n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the script to s3\n",
    "codeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=\"code\")\n",
    "\n",
    "# where was it uploaded\n",
    "print(codeupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# run the data processing on a dedicated vm\n",
    "sklearn_processor.run(\n",
    "    code=codeupload,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=f\"s3://{rawbucket}/data\",\n",
    "        destination='/opt/ml/processing/input')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='train_data',\n",
    "        source='/opt/ml/processing/train',\n",
    "        destination=f\"s3://{rawbucket}/train\"),\n",
    "        ProcessingOutput(output_name='test_data',\n",
    "        source=\"/opt/ml/processing/test\",\n",
    "        destination=f\"s3://{rawbucket}/test\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# give us some info on the process\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "# show us what happened with the processing\n",
    "print(preprocessing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have experimental capabilities\n",
    "\n",
    "!pip install sagemaker-experiments \n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SageMaker Experiment\n",
    "mmm_experiment = Experiment.create(\n",
    "    experiment_name=f\"mmm-train-{int(time.time())}\", \n",
    "    description=\"Predict sales given a marketing mix\",\n",
    "    sagemaker_boto_client=sm\n",
    ")\n",
    "\n",
    "# show experiment details\n",
    "print(mmm_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tracking parameters used in the Pre-processing pipeline.\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mmm-raw-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/data\")\n",
    "    tracker.log_input(name=\"mmm-train-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/train\")\n",
    "    tracker.log_input(name=\"mmm-test-dataset\", media_type=\"s3/uri\", value=f\"s3://{rawbucket}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the trial\n",
    "trial_name = f\"mmm-training-job-{int(time.time())}\"\n",
    "\n",
    "# create a new trial\n",
    "mmm_trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=mmm_experiment.experiment_name,\n",
    "    sagemaker_boto_client=sm\n",
    ")\n",
    "\n",
    "# add a trial component\n",
    "mmm_trial.add_trial_component(tracker.trial_component)\n",
    "\n",
    "# give the training run a name\n",
    "mmm_training_job_name = \"mmm-training-job-{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# get the container image for xgboost\n",
    "container = get_image_uri(region, 'xgboost', '1.0-1')\n",
    "\n",
    "# set your hyperparams (this is a regression problem)\n",
    "hyperparameters = {\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"100\"\n",
    "}\n",
    "\n",
    "# specify the xgboost estimator and training instance vm size\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container, \n",
    "    role=role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.m5.2xlarge', \n",
    ")\n",
    "\n",
    "# train\n",
    "estimator.fit(inputs={\n",
    "        \"train\": f\"s3://{rawbucket}/train\"\n",
    "    },\n",
    "    job_name=mmm_training_job_name,\n",
    "    experiment_config={\n",
    "        \"TrialName\": mmm_trial.trial_name, #log training job in Trials for lineage\n",
    "        \"TrialComponentDisplayName\": \"Training\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most recent trained estimator\n",
    "estimator.latest_training_job.wait(logs=\"None\")\n",
    "\n",
    "# find where it is stored\n",
    "artifact = sm.describe_training_job(\n",
    "    TrainingJobName=estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "# tell us\n",
    "print(f\"Model artifact persisted at {artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# deploy the xgboost estimator, make sure it will take a csv input format\n",
    "xgb_predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    \"\"\" \n",
    "    prediction function for xgboost algorithm that takes\n",
    "    a CSV input\n",
    "    \"\"\"\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "predicted = predict(pd.read_csv(f\"s3://{rawbucket}/test/X_test.csv\", index_col=0).to_numpy())\n",
    "\n",
    "# actual values\n",
    "actual = pd.read_csv(f\"s3://{rawbucket}/test/y_test.csv\", index_col=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rmse = metrics.mean_squared_error(actual, predicted, squared=False)\n",
    "\n",
    "print(f\"Test-set RMSE = {rmse}\")\n",
    "\n",
    "# show a plot of test-set predictions and actual values\n",
    "plt.scatter(actual, predicted)\n",
    "plt.plot([0, 25], [0, 25], '--', linewidth=1, c=\"b\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=\"sagemaker-xgboost-2021-09-14-12-01-40-203\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb\n",
    "\n",
    "https://aws.amazon.com/getting-started/hands-on/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=gs_card\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/simplify-machine-learning-with-xgboost-and-amazon-sagemaker/"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
